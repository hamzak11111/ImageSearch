{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from transformers import ImageGPTFeatureExtractor, ImageGPTModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_path = \"../../1) Data_Collection/OID/Dataset/train\"\n",
    "output = \"imagegpt_embeddings\"\n",
    "\n",
    "bin_file = f'{output}/imageGPTIndex.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DINOv2 model (replace with the actual loading function or model URL)\n",
    "def load_imagegpt_model():\n",
    "    feature_extractor_gpt = ImageGPTFeatureExtractor.from_pretrained('openai/imagegpt-small')\n",
    "    model_gpt = ImageGPTModel.from_pretrained('openai/imagegpt-small')\n",
    "    return feature_extractor_gpt, model_gpt\n",
    "\n",
    "# Preprocess the image using ImageGPT's feature extractor\n",
    "def preprocess_image(feature_extractor_gpt, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is in RGB mode\n",
    "    inputs = feature_extractor_gpt(images=image, return_tensors=\"pt\")\n",
    "    return inputs # Return preprocessed image tensor\n",
    "\n",
    "# Generate embeddings using ImageGPT\n",
    "def generate_embeddings(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**image_tensor)\n",
    "\n",
    "    return outputs.last_hidden_state.cpu().numpy().mean(axis=1)\n",
    "\n",
    "# Save embeddings to a .bin file\n",
    "def save_embeddings_to_bin(file_path):\n",
    "    faiss.write_index(index, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main(image_path, output_path):\n",
    "\n",
    "    global total_time, total_images\n",
    "    \n",
    "    feature_extractor_gpt, model = load_imagegpt_model()\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    image_tensor = preprocess_image(feature_extractor_gpt, image_path)\n",
    "    embeddings = generate_embeddings(model, image_tensor)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    total_time += elapsed_time\n",
    "    total_images += 1\n",
    "\n",
    "    index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\transformers\\models\\imagegpt\\feature_extraction_imagegpt.py:28: FutureWarning: The class ImageGPTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ImageGPTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "indexes = {}\n",
    "idx = 0\n",
    "\n",
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "for one_category in os.listdir(images_folder_path):\n",
    "    one_category_path = os.path.join(images_folder_path, one_category)\n",
    "\n",
    "    all_images_in_category_folder = [x for x in os.listdir(one_category_path) if x.endswith(\"jpg\")]\n",
    "\n",
    "    for img in all_images_in_category_folder:\n",
    "\n",
    "        img_path = os.path.join(one_category_path, img)\n",
    "        \n",
    "        output_path = os.path.join(output, img[:-3]+\"bin\")\n",
    "\n",
    "        main(img_path, output_path)\n",
    "\n",
    "        indexes[idx] = img_path\n",
    "        idx += 1\n",
    "\n",
    "save_embeddings_to_bin(bin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 125.17 seconds\n",
      "Average Time per Image: 2.28 seconds\n"
     ]
    }
   ],
   "source": [
    "average_time = total_time / total_images if total_images > 0 else 0\n",
    "\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "print(f\"Average Time per Image: {average_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output}/indices.json', 'w') as file:\n",
    "    json.dump(indexes, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
