{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from transformers import AutoProcessor, AutoTokenizer, CLIPModel\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_path = \"../../1) Data_Collection/OID/Dataset/train\"\n",
    "output = \"clip_embeddings\"\n",
    "bin_file = 'clipIndex.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DINOv2 model (replace with the actual loading function or model URL)\n",
    "def load_clip_model():\n",
    "\n",
    "    model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor_clip = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    return processor_clip, model_clip\n",
    "\n",
    "# Preprocess the image using ImageGPT's feature extractor\n",
    "def preprocess_image(processor_clip, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure image is in RGB mode\n",
    "    inputs = processor_clip(images=image, return_tensors=\"pt\")\n",
    "    return inputs # Return preprocessed image tensor\n",
    "\n",
    "# Generate embeddings using ImageGPT\n",
    "def generate_embeddings(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**image_tensor)\n",
    "\n",
    "    return outputs.cpu().numpy()\n",
    "\n",
    "# Save embeddings to a .bin file\n",
    "def save_embeddings_to_bin(file_path):\n",
    "    faiss.write_index(index, file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main(image_path, output_path):\n",
    "\n",
    "    global total_time, total_images\n",
    "    \n",
    "    feature_extractor_clip, model = load_clip_model()\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    image_tensor = preprocess_image(feature_extractor_clip, image_path)\n",
    "    embeddings = generate_embeddings(model, image_tensor)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    total_time += elapsed_time\n",
    "    total_images += 1\n",
    "\n",
    "    index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "indexes = {}\n",
    "idx = 0\n",
    "\n",
    "for one_category in os.listdir(images_folder_path):\n",
    "    one_category_path = os.path.join(images_folder_path, one_category)\n",
    "\n",
    "    all_images_in_category_folder = [x for x in os.listdir(one_category_path) if x.endswith(\"jpg\")]\n",
    "\n",
    "    for img in all_images_in_category_folder:\n",
    "\n",
    "        img_path = os.path.join(one_category_path, img)\n",
    "        \n",
    "        output_path = os.path.join(output, bin_file)\n",
    "\n",
    "        main(img_path, output_path)\n",
    "\n",
    "        indexes[idx] = img_path\n",
    "        idx += 1\n",
    "\n",
    "save_embeddings_to_bin(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 8.95 seconds\n",
      "Average Time per Image: 0.16 seconds\n"
     ]
    }
   ],
   "source": [
    "average_time = total_time / total_images if total_images > 0 else 0\n",
    "\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "print(f\"Average Time per Image: {average_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output}/indices.json', 'w') as file:\n",
    "    json.dump(indexes, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
